# Bandits
This package provide a framework for developing and comparing various Bandit algorithms

## Available Algorithms
1. ϵ-greedy
   1. [ϵ-greedy](https://github.com/UmaArunachalam8/Bandits.jl/blob/master/doc/e-greedy.md)
   2. [ϵ_n greedy](https://github.com/UmaArunachalam8/Bandits.jl/blob/master/doc/epsilon-n-greedy.md)
2. Upper Confidence Bound Policies
   1. [UCB1](https://github.com/UmaArunachalam8/Bandits.jl/blob/master/doc/UCB1.md)
   2. [UCB2](https://github.com/UmaArunachalam8/Bandits.jl/blob/master/doc/UCB2.md)
   3. [UCB-Normal](https://github.com/UmaArunachalam8/Bandits.jl/blob/master/doc/UCB-NORMAL.md)
   4. [Discounted-UCB](https://github.com/UmaArunachalam8/Bandits.jl/blob/master/doc/DISCOUNTED%20UCB.md)
   5. [Sliding Window UCB](https://github.com/UmaArunachalam8/Bandits.jl/blob/master/doc/SLIDING-WINDOW-UCB.md)
3. Thompson Sampling
   1. Thompson Sampling
   2. Dynamic Thompson Sampling
   3. Optimistic Thompson Sampling
4. EXP3
   1. [EXP3](https://github.com/UmaArunachalam8/Bandits.jl/blob/master/doc/EXP3.md)
   2. EXP3.1
   3. EXP3-IX
   4. [EXP3P](https://github.com/UmaArunachalam8/Bandits.jl/blob/master/doc/EXP3P.md)
   5. [EXP3S](https://github.com/UmaArunachalam8/Bandits.jl/blob/master/doc/EXP3S.md)
5. SoftMax
6. REXP3

## Available Arm Models
1. Bernoulli
2. Beta
3. Normal
4. Sinusoidal (without noise)
5. Pulse (without noise)
6. Square
7. Variational (without noise)
